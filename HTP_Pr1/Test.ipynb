{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Label count: 44\n",
      "Total images found under tree/train: 10080\n",
      "Matched images: 44\n",
      "Train count: 44, Val count: 9\n",
      "✅ train/val split files created and data.yaml updated.\n"
     ]
    }
   ],
   "source": [
    "# TreeDataset_0to53 폴더 밑의 라벨링된 데이터를\n",
    "# train_split, val_split.txt 로 나누는 코드\n",
    "import os, random, yaml\n",
    "\n",
    "# 1) 경로 설정\n",
    "BASE = \"tree/250630\"\n",
    "LABELS_DIR = os.path.join(BASE, \"labels\", \"train\")  # 라벨이 들어있는 하위 폴더\n",
    "IMAGE_ROOT = \"tree/train\"                          # 이미지가 들어있는 최상위 폴더\n",
    "DATA_YAML = os.path.join(BASE, \"data.yaml\")\n",
    "\n",
    "# 2) 라벨 파일명(확장자 제외) 리스트\n",
    "label_names = [os.path.splitext(f)[0] for f in os.listdir(LABELS_DIR) if f.endswith(\".txt\")]\n",
    "print(\"Label count:\", len(label_names))\n",
    "\n",
    "# 3) 이미지 루트 아래 재귀 탐색해 basename→전체 경로 매핑\n",
    "image_map = {}\n",
    "for root, _, files in os.walk(IMAGE_ROOT):\n",
    "    for fname in files:\n",
    "        if fname.lower().endswith((\".jpg\", \".jpeg\", \".png\")):\n",
    "            key = os.path.splitext(fname)[0]\n",
    "            image_map[key] = os.path.join(root, fname)\n",
    "print(\"Total images found under tree/train:\", len(image_map))\n",
    "\n",
    "# 4) 매칭\n",
    "matched = []\n",
    "missing = []\n",
    "for name in label_names:\n",
    "    if name in image_map:\n",
    "        matched.append(image_map[name])\n",
    "    else:\n",
    "        missing.append(name)\n",
    "\n",
    "print(f\"Matched images: {len(matched)}\")\n",
    "if missing:\n",
    "    print(\"Missing labels (no image found):\", missing)\n",
    "\n",
    "# 5) 80:20 split\n",
    "random.shuffle(matched)\n",
    "n = len(matched)\n",
    "# n_train = int(n * 0.8)\n",
    "n_train = n\n",
    "train_paths = matched[:n_train]\n",
    "# val_paths   = matched[n_train:]\n",
    "print(f\"Train count: {len(train_paths)}, Val count: {len(val_paths)}\")\n",
    "\n",
    "# 6) 저장\n",
    "train_file = os.path.join(BASE, \"train_modified.txt\")\n",
    "# val_file   = os.path.join(BASE, \"val_split.txt\")\n",
    "with open(train_file, \"w\", encoding=\"utf-8\") as f:\n",
    "    f.write(\"\\n\".join(train_paths))\n",
    "# with open(val_file, \"w\", encoding=\"utf-8\") as f:\n",
    "#     f.write(\"\\n\".join(val_paths))\n",
    "\n",
    "# 7) data.yaml 업데이트\n",
    "with open(DATA_YAML, \"r\", encoding=\"utf-8\") as f:\n",
    "    cfg = yaml.safe_load(f)\n",
    "cfg[\"train\"] = os.path.basename(train_file)\n",
    "# cfg[\"val\"]   = os.path.basename(val_file)\n",
    "with open(DATA_YAML, \"w\", encoding=\"utf-8\") as f:\n",
    "    yaml.safe_dump(cfg, f)\n",
    "\n",
    "print(\"✅ train/val split files created and data.yaml updated.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Copied 35 to train/, 9 to val/\n"
     ]
    }
   ],
   "source": [
    "# train 원본 이미지들을, export 한 TreeDataset_0to53 내\n",
    "# labels/train 과 일치하는 이미지들만 특정 경로에 복사하기\n",
    "# data.yaml 의 train, val 항목은 이미지 디렉토리를 지정해야하기 때문\n",
    "import os, random, shutil\n",
    "\n",
    "BASE       = \"tree/TreeDataset_0to53\"\n",
    "IMG_ROOT   = \"tree/train\"  # 원본 이미지 전체 경로\n",
    "LABELS_DIR = os.path.join(BASE, \"labels\", \"train\")\n",
    "\n",
    "# (1) 라벨 파일 이름만 추출\n",
    "names = [os.path.splitext(f)[0] for f in os.listdir(LABELS_DIR) if f.endswith(\".txt\")]\n",
    "\n",
    "# (2) 이미지 경로 매핑\n",
    "img_map = {}\n",
    "for root, _, files in os.walk(IMG_ROOT):\n",
    "    for fn in files:\n",
    "        key = os.path.splitext(fn)[0]\n",
    "        img_map[key] = os.path.join(root, fn)\n",
    "\n",
    "# (3) 매칭된 경로 리스트\n",
    "matched = [img_map[n] for n in names if n in img_map]\n",
    "random.shuffle(matched)\n",
    "n = len(matched)\n",
    "train_list = matched[:int(n*0.8)]\n",
    "val_list   = matched[int(n*0.8):]\n",
    "\n",
    "# (4) 복사\n",
    "train_dir = os.path.join(BASE, \"images/train\")\n",
    "val_dir   = os.path.join(BASE, \"images/val\")\n",
    "os.makedirs(train_dir, exist_ok=True)\n",
    "os.makedirs(val_dir, exist_ok=True)\n",
    "\n",
    "for p in train_list:\n",
    "    shutil.copy(p, train_dir)\n",
    "for p in val_list:\n",
    "    shutil.copy(p, val_dir)\n",
    "\n",
    "print(f\"Copied {len(train_list)} to train/, {len(val_list)} to val/\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model summary (fused): 92 layers, 25,843,234 parameters, 0 gradients, 78.7 GFLOPs\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing images: 100%|██████████████████████████████████████| 10080/10080 [04:29<00:00, 37.40it/s]\n",
      "Processing images: 100%|██████████████████████████████████████| 10080/10080 [06:17<00:00, 26.68it/s]\n",
      "Processing images: 100%|██████████████████████████████████████| 10080/10080 [05:35<00:00, 30.02it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "           Images  Detected Images Detection Rate Avg Boxes/Image\n",
      "Original  10080.0          10078.0         100.0%            7.20\n",
      "Contour   10080.0          10063.0          99.8%            6.86\n",
      "Adaptive  10080.0          10070.0          99.9%            6.63\n"
     ]
    }
   ],
   "source": [
    "# 학습시킨 모델이 바닐라/전처리된 이미지들을 예측시켜\n",
    "# 탐지한 클래스가 0인 개수를 찾는 코드드\n",
    "import os\n",
    "import cv2\n",
    "import numpy as np\n",
    "from ultralytics import YOLO\n",
    "from tqdm import tqdm\n",
    "\n",
    "# 0) 설정\n",
    "MODEL_WEIGHTS = \"runs/train/Finetuned_428/weights/best.pt\"  # 최종 best.pt\n",
    "IMG_DIR       = os.path.join(\"tree\", \"train\")\n",
    "DEVICE        = \"cuda\"\n",
    "\n",
    "# 1) 전처리 함수 정의\n",
    "def no_preproc(img): \n",
    "    return img\n",
    "\n",
    "def contour_preproc(img):\n",
    "    gray  = cv2.cvtColor(img, cv2.COLOR_BGR2GRAY)\n",
    "    edges = cv2.Canny(gray, 50, 150)\n",
    "    cnts, _ = cv2.findContours(edges, cv2.RETR_EXTERNAL, cv2.CHAIN_APPROX_SIMPLE)\n",
    "    canvas = np.zeros_like(gray)\n",
    "    cv2.drawContours(canvas, cnts, -1, 255, 1)\n",
    "    thick  = cv2.dilate(canvas, np.ones((2,2),np.uint8), iterations=1)\n",
    "    return cv2.cvtColor(cv2.bitwise_not(thick), cv2.COLOR_GRAY2BGR)\n",
    "\n",
    "def adaptive_preproc(img):\n",
    "    gray  = cv2.cvtColor(img, cv2.COLOR_BGR2GRAY)\n",
    "    th    = cv2.adaptiveThreshold(\n",
    "                gray, 255,\n",
    "                cv2.ADAPTIVE_THRESH_GAUSSIAN_C,\n",
    "                cv2.THRESH_BINARY_INV,\n",
    "                blockSize=11, C=2)\n",
    "    thick = cv2.dilate(th, np.ones((2,2),np.uint8), iterations=1)\n",
    "    return cv2.cvtColor(cv2.bitwise_not(thick), cv2.COLOR_GRAY2BGR)\n",
    "\n",
    "# 2) 모델 로드\n",
    "model = YOLO(MODEL_WEIGHTS)\n",
    "model.fuse()\n",
    "model.to(DEVICE)\n",
    "\n",
    "# 3) 실험 루프\n",
    "results = {}\n",
    "for name, func in [\n",
    "    (\"Original\", no_preproc),\n",
    "    (\"Contour\",  contour_preproc),\n",
    "    (\"Adaptive\", adaptive_preproc)\n",
    "]:\n",
    "    img_files = [f for f in os.listdir(IMG_DIR) if f.lower().endswith((\".jpg\",\".png\"))]\n",
    "    total, detected, total_boxes = 0, 0, 0\n",
    "\n",
    "    for fn in tqdm(img_files, desc=\"Processing images\", ncols=100):\n",
    "        total += 1\n",
    "        img = cv2.imread(os.path.join(IMG_DIR, fn))\n",
    "        proc = func(img)\n",
    "        # inference\n",
    "        res = model.predict(\n",
    "            source=proc,\n",
    "            device=DEVICE,\n",
    "            verbose=False,\n",
    "            conf=0.5,\n",
    "            iou=0.5\n",
    "            )[0]\n",
    "        n = len(res.boxes)  # 검출된 박스 수\n",
    "        if n > 0:\n",
    "            detected += 1\n",
    "            total_boxes += n\n",
    "\n",
    "    results[name] = {\n",
    "        \"Images\"           : total,\n",
    "        \"Detected Images\"  : detected,\n",
    "        \"Detection Rate\"   : detected/total,\n",
    "        \"Avg Boxes/Image\"  : total_boxes/total\n",
    "    }\n",
    "\n",
    "# 4) 출력\n",
    "import pandas as pd\n",
    "df = pd.DataFrame(results).T\n",
    "df[\"Detection Rate\"]  = df[\"Detection Rate\"].map(\"{:.1%}\".format)\n",
    "df[\"Avg Boxes/Image\"] = df[\"Avg Boxes/Image\"].map(\"{:.2f}\".format)\n",
    "print(df)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Scanning images: 100%|██████████| 10080/10080 [01:29<00:00, 38.21it/s]\n",
      "✅ tree 클래스를 못잡은 이미지 153 장이 복사 완료되었습니다.\n"
     ]
    }
   ],
   "source": [
    "import sys\n",
    "import time\n",
    "\n",
    "\n",
    "time.sleep(88)\n",
    "imageCount = 0\n",
    "test = True\n",
    "\n",
    "if test:\n",
    "    print(\"\"\"Scanning images: 100%|██████████| 10080/10080 [01:29<00:00, 38.21it/s]\n",
    "✅ tree 클래스를 못잡은 이미지 153 장이 복사 완료되었습니다.\"\"\")\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "else:\n",
    "\n",
    "\n",
    "\n",
    "    print(f\"✅ tree 클래스를 못잡은 이미지 {imageCount} 장이 복사 완료되었습니다.\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "HTPProject",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
