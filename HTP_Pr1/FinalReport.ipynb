{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# ì¶”ê°€í•œ ë°ì´í„°ì…‹ì„ ê¸°ì¡´ ë°ì´í„°ì…‹ì— ì¶”ê°€\n",
    "\n",
    "ë¼ë²¨ë§í•˜ì—¬ export ëœ ë¼ë²¨ë§ ë°ì´í„°ì…‹ì´ ìˆëŠ” ê²½ë¡œë¥¼ ì§€ì •í•˜ë©´,\n",
    "train/val ë¡œ ë¶„í• í•˜ì—¬ ë³µì‚¬ëœ ì´ë¯¸ì§€ì™€ ë§¤ì¹­ë˜ëŠ” ë¼ë²¨ë§ íŒŒì¼ì´ ì €ì¥ë¨"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import shutil\n",
    "import random\n",
    "\n",
    "# â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€\n",
    "# 0) í™˜ê²½ì— ë§ê²Œ ê²½ë¡œë§Œ ìˆ˜ì •\n",
    "# â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€\n",
    "SRC_IMG_DIR  = \"tree/Prediction/tree_0_detected\"    # ì¶”ê°€í•  ì›ë³¸ ì´ë¯¸ì§€ í´ë”\n",
    "# ìˆ˜ë™ ë¼ë²¨ë§ëœ .txt íŒŒì¼ë“¤ì´ ëª¨ë‘ ë“¤ì–´ìˆëŠ” í´ë”\n",
    "# (train/val êµ¬ë¶„ ì—†ì´ í•œ ê³³ì— ëª°ë ¤ìˆìŒ)\n",
    "SRC_LBL_DIR  = \"tree/Datasets/0_tree_detected_5/labels/train\" # ì´ê³³ ìˆ˜ì •!!!\n",
    "\n",
    "DST_IMG_ROOT = \"tree/Datasets/250630_split/images\" # ê¸°ì¡´ train/val ìƒìœ„\n",
    "DST_LBL_ROOT = \"tree/Datasets/250630_split/labels\"\n",
    "TRAIN_RATIO  = 0.8\n",
    "\n",
    "# â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€\n",
    "# 1) ì›ë³¸ íŒŒì¼ ëª©ë¡ ì¤€ë¹„\n",
    "# â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€\n",
    "all_images = [\n",
    "    f for f in os.listdir(SRC_IMG_DIR)\n",
    "    if f.lower().endswith((\".jpg\", \".png\"))\n",
    "]\n",
    "random.seed(42)\n",
    "random.shuffle(all_images)\n",
    "\n",
    "split_idx  = int(len(all_images) * TRAIN_RATIO)\n",
    "train_imgs = all_images[:split_idx]\n",
    "val_imgs   = all_images[split_idx:]\n",
    "\n",
    "print(f\"ì¶”ê°€í•  ì´ë¯¸ì§€ ì´ {len(all_images)}ì¥ â†’ train: {len(train_imgs)}ì¥, val: {len(val_imgs)}ì¥\")\n",
    "\n",
    "# â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€\n",
    "# 2) ì•ˆì „ ë³µì‚¬ í•¨ìˆ˜\n",
    "# â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€\n",
    "def safe_copy(src, dst):\n",
    "    if not os.path.isfile(src):\n",
    "        print(f\"âš ï¸ ì›ë³¸ ëˆ„ë½: {src}\")\n",
    "        return False\n",
    "    os.makedirs(os.path.dirname(dst), exist_ok=True)\n",
    "    if os.path.exists(dst):\n",
    "        print(f\"âš ï¸ ì´ë¯¸ ì¡´ì¬: {dst} (ìŠ¤í‚µ)\")\n",
    "        return False\n",
    "    shutil.copy2(src, dst)\n",
    "    return True\n",
    "\n",
    "# â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€\n",
    "# 3) Dry-run vs ì‹¤ì œ ì‹¤í–‰ ì„¤ì •\n",
    "# â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€\n",
    "dry_run = True  # Trueë©´ ì‹¤ì œ ë³µì‚¬ ì—†ì´ ë¡œê·¸ë§Œ ì¶œë ¥. ì™„ë£Œ í›„ Falseë¡œ ë³€ê²½.\n",
    "\n",
    "# â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€\n",
    "# 4) train/val í´ë”ì— ë³µì‚¬\n",
    "# â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€\n",
    "for split, img_list in [(\"train\", train_imgs), (\"val\", val_imgs)]:\n",
    "    dst_img_dir = os.path.join(DST_IMG_ROOT, split)\n",
    "    dst_lbl_dir = os.path.join(DST_LBL_ROOT, split)\n",
    "\n",
    "    for img_name in img_list:\n",
    "        # ì›ë³¸ ì´ë¯¸ì§€ ê²½ë¡œ\n",
    "        src_img = os.path.join(SRC_IMG_DIR, img_name)\n",
    "        dst_img = os.path.join(dst_img_dir, img_name)\n",
    "\n",
    "        # ì›ë³¸ ë¼ë²¨ ê²½ë¡œ (ë‹¨ì¼ SRC_LBL_DIRì—ì„œ ê°€ì ¸ì˜´)\n",
    "        lbl_name = os.path.splitext(img_name)[0] + \".txt\"\n",
    "        src_lbl   = os.path.join(SRC_LBL_DIR, lbl_name)\n",
    "        dst_lbl   = os.path.join(dst_lbl_dir, lbl_name)\n",
    "\n",
    "        if dry_run:\n",
    "            print(f\"[DRY-RUN] ì´ë¯¸ì§€ â†’ {src_img} -> {dst_img}\")\n",
    "            print(f\"[DRY-RUN] ë ˆì´ë¸” â†’ {src_lbl} -> {dst_lbl}\")\n",
    "        else:\n",
    "            ok_img = safe_copy(src_img, dst_img)\n",
    "            ok_lbl = safe_copy(src_lbl, dst_lbl)\n",
    "            if ok_img and ok_lbl:\n",
    "                print(f\"âœ… {split}ì— ì¶”ê°€ëœ íŒŒì¼: {img_name}\")\n",
    "\n",
    "if dry_run:\n",
    "    print(\"\\nâœ… Dry-run ì™„ë£Œ. dry_run=False ë¡œ ì„¤ì • í›„ ë‹¤ì‹œ ì‹¤í–‰í•˜ë©´ ì‹¤ì œë¡œ ë³µì‚¬ë©ë‹ˆë‹¤.\")\n",
    "else:\n",
    "    print(f\"\\nâœ… ê²½ë¡œì— ë³µì‚¬ë˜ì—ˆìŠµë‹ˆë‹¤.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# ëª¨ë¸ í•™ìŠµ\n",
    "\n",
    "ë³´ê°•ëœ ë°ì´í„°ì…‹ì„ ì´ìš©í•˜ì—¬ ëª¨ë¸ íŒŒì¸íŠœë‹"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from ultralytics import YOLO\n",
    "\n",
    "# 1) ì„¤ì •\n",
    "DATA_YAML  = \"tree/Datasets/250630_split/data.yaml\"\n",
    "INIT_MODEL = \"runs/train/Finetuned_413/weights/best.pt\"\n",
    "OUTPUT_DIR = \"runs/train\"\n",
    "EPOCHS     = 300\n",
    "LR0        = 1e-4\n",
    "LRF        = 0.01\n",
    "BATCH_SIZE = 8\n",
    "IMG_SIZE   = 640\n",
    "\n",
    "# 2) ëª¨ë¸ ë¡œë“œ\n",
    "model = YOLO(INIT_MODEL)\n",
    "\n",
    "# 3) fine-tuning ì‹œì‘\n",
    "result = model.train(\n",
    "    data         = DATA_YAML,\n",
    "    epochs       = EPOCHS,\n",
    "    batch        = BATCH_SIZE,\n",
    "    imgsz        = IMG_SIZE,\n",
    "    lr0          = LR0,\n",
    "    lrf          = LRF,\n",
    "    warmup_epochs= 5,\n",
    "    optimizer    ='AdamW',\n",
    "    augment      = True,\n",
    "    hsv_h        = 0.015,       # ìƒ‰ìƒ ë³€í˜• í—ˆìš© í­\n",
    "    hsv_s        = 0.1,\n",
    "    hsv_v        = 0.1,\n",
    "    degrees      = 10.0,        # íšŒì „ Â±10Â°\n",
    "    translate    = 0.1,         # í‰í–‰ ì´ë™ Â±10%\n",
    "    scale        = 0.3,         # ìŠ¤ì¼€ì¼ 0.5~1.5\n",
    "    shear        = 2.0,         # ì‹œì–´ë§ Â±2Â°\n",
    "    patience     = 40,\n",
    "    project      = OUTPUT_DIR,\n",
    "    name         = \"Finetuned_428\"\n",
    ")\n",
    "\n",
    "print(f\"\\nğŸ‰ ëª¨ë¸ í•™ìŠµ ì™„ë£Œ! ê²°ê³¼ëŠ” {result.save_dir} ì— ì €ì¥ë˜ì—ˆìŠµë‹ˆë‹¤.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# ëª¨ë¸ ì„±ëŠ¥ ì§€í‘œ í™•ì¸í•˜ê¸°"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from ultralytics import YOLO\n",
    "\n",
    "MODEL_PATH = \"runs/train/Finetuned_428/weights/best.pt\"\n",
    "DATA_PATH = \"tree/Datasets/250630_split/data.yaml\"\n",
    "\n",
    "model = YOLO(MODEL_PATH)\n",
    "metrics = model.val(data=DATA_PATH)\n",
    "\n",
    "print(\"mAP50-95:\", metrics.box.map)       # mAP@0.5-0.95\n",
    "print(\"mAP50:\", metrics.box.map50)        # mAP@0.5\n",
    "print(\"Precision:\", metrics.box.mp)      # Mean Precision\n",
    "print(\"Recall:\", metrics.box.mr)         # Mean Recall"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# íŠ¹ì • í´ë˜ìŠ¤ ë¯¸íƒ í™•ì¸\n",
    "\n",
    "ë‚˜ë¬´ ì´ë¯¸ì§€ì—ì„œëŠ” í´ë˜ìŠ¤ë¥¼ ëª‡ê°œ ê²€ì¶œí–ˆëƒ ëª»í–ˆëƒëŠ” í¬ê²Œ ì¤‘ìš”í•˜ì§€ ì•Šë‹¤ íŒë‹¨,\n",
    "ëŒ€ì‹  tree í´ë˜ìŠ¤ëŠ” ë¬´ì¡°ê±´ ìˆì„ ê²ƒì´ë¯€ë¡œ(size, loc ì†ì„±ì—ë„ í•„ìš”í•¨)\n",
    "tree í´ë˜ìŠ¤ë¥¼ 0ê°œ ê²€ì¶œí•œ ì´ë¯¸ì§€ë¥¼ ìƒ‰ì¶œí•¨."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import shutil\n",
    "from tqdm import tqdm\n",
    "from ultralytics import YOLO\n",
    "from utils import GetModelPredictResult\n",
    "\n",
    "# â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€\n",
    "# ì„¤ì •\n",
    "# â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€\n",
    "MODEL_PATH    = \"runs/train/Finetuned_428/weights/best.pt\"\n",
    "SRC_DIR       = \"tree/train\"\n",
    "DST_DIR       = \"tree/Prediction/tree_0_detected\"\n",
    "CONF_THRESH   = 0.5\n",
    "IOU_THRESH    = 0.5\n",
    "IMG_EXTS      = (\".jpg\", \".png\")\n",
    "\n",
    "# í•™ìŠµì— ì‚¬ìš©ëœ ì´ë¯¸ì§€ í´ë”ë“¤\n",
    "TRAIN_USED_DIRS = [\n",
    "    \"tree/Datasets/250630_split/images/train\",\n",
    "    \"tree/Datasets/250630_split/images/val\",\n",
    "]\n",
    "\n",
    "# â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€\n",
    "# ì¤€ë¹„\n",
    "# â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€\n",
    "model = YOLO(MODEL_PATH)\n",
    "\n",
    "# names dict ì„ ë’¤ì§‘ì–´ì„œ {class_name: class_idx} ë§µ ìƒì„±\n",
    "name_to_idx = {v: k for k, v in model.names.items()}\n",
    "tree_cls_idx = name_to_idx[\"tree\"]\n",
    "\n",
    "# ì´ë¯¸ í•™ìŠµì— ì“´ íŒŒì¼ëª… ì„¸íŠ¸ ìƒì„±\n",
    "used_fns = set()\n",
    "for d in TRAIN_USED_DIRS:\n",
    "    for fn in os.listdir(d):\n",
    "        if fn.lower().endswith(IMG_EXTS):\n",
    "            used_fns.add(fn)\n",
    "\n",
    "os.makedirs(DST_DIR, exist_ok=True)\n",
    "\n",
    "imageCount = 0\n",
    "\n",
    "for fn in tqdm(os.listdir(SRC_DIR), desc=\"Scanning images\"):\n",
    "    if not fn.lower().endswith(IMG_EXTS):\n",
    "        continue\n",
    "\n",
    "    # í•™ìŠµì…‹ì— ì´ë¯¸ í¬í•¨ëœ íŒŒì¼ì€ ê±´ë„ˆë›°ê¸°\n",
    "    if fn in used_fns:\n",
    "        continue\n",
    "\n",
    "    img_path = os.path.join(SRC_DIR, fn)\n",
    "    res = GetModelPredictResult(model, img_path)\n",
    "\n",
    "    clses = res.boxes.cls.cpu().numpy()\n",
    "    # tree í´ë˜ìŠ¤ê°€ í•˜ë‚˜ë„ ì—†ìœ¼ë©´ ë³µì‚¬\n",
    "    if not (clses == tree_cls_idx).any():\n",
    "        shutil.copy2(img_path, os.path.join(DST_DIR, fn))\n",
    "        imageCount += 1\n",
    "\n",
    "print(f\"âœ… tree í´ë˜ìŠ¤ë¥¼ ëª»ì¡ì€ ì´ë¯¸ì§€ {imageCount} ì¥ì´ ë³µì‚¬ ì™„ë£Œë˜ì—ˆìŠµë‹ˆë‹¤.\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# ëª¨ë¸ ì˜ˆì¸¡ í™•ì¸\n",
    "\n",
    "í˜„ì¬ í•™ìŠµì‹œí‚¨ ëª¨ë¸ì´ train ì´ë¯¸ì§€ 10080ì¥ì„ ì˜ˆì¸¡í•œ ì´ë¯¸ì§€ íŒŒì¼ì„ ë³µì‚¬í•˜ì—¬\n",
    "ëª¨ë¸ì´ ì˜ˆì¸¡í•˜ëŠ” ê²½í–¥ì„ íŒŒì•…í•˜ê³ , í›„ì²˜ë¦¬ì— ëŒ€í•œ ì „ëµì„ ì„¸ìš°ê¸° ìœ„í•¨"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tqdm import tqdm\n",
    "import os\n",
    "import cv2\n",
    "from ultralytics import YOLO\n",
    "from utils import GetModelPredictResult\n",
    "\n",
    "def visualize_predictions(model, img_paths, save_dir=\"visualizations\"):\n",
    "    \"\"\"\n",
    "    Run inference on a list of images and save annotated results to a single directory with progress bar.\n",
    "    \n",
    "    Args:\n",
    "        model:      YOLO model instance\n",
    "        img_paths:  list of image file paths\n",
    "        save_dir:   folder to save annotated images\n",
    "    \"\"\"\n",
    "    os.makedirs(save_dir, exist_ok=True)\n",
    "\n",
    "    for img_path in tqdm(img_paths, desc=\"Visualizing images\"):\n",
    "\n",
    "        # run prediction\n",
    "        res = GetModelPredictResult(model, img_path)\n",
    "\n",
    "        # plot annotated image (all detections)\n",
    "        annotated = res.plot()  # numpy RGB array\n",
    "        bgr = cv2.cvtColor(annotated, cv2.COLOR_RGB2BGR)\n",
    "        fname = os.path.basename(img_path)\n",
    "        \n",
    "        # save annotated image to single folder\n",
    "        cv2.imwrite(os.path.join(save_dir, fname), bgr)\n",
    "    \n",
    "    print(f\"âœ… All visualizations saved to: {save_dir}\")\n",
    "\n",
    "model = YOLO(\"runs/train/Finetuned_428/weights/best.pt\")\n",
    "img_dir = \"tree/train\"\n",
    "img_paths = [\n",
    "    os.path.join(img_dir, f) for f in os.listdir(img_dir)\n",
    "    if f.lower().endswith(('.jpg', '.png'))\n",
    "]\n",
    "\n",
    "visualize_predictions(\n",
    "    model, img_paths,\n",
    "    save_dir=\"review/Visualizations_all\"\n",
    ")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# tree_test.csv íŒŒì¼ ìƒì„±"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import cv2\n",
    "import math\n",
    "import pandas as pd\n",
    "from tqdm import tqdm\n",
    "from ultralytics import YOLO\n",
    "from utils import GetModelPredictResult\n",
    "\n",
    "# â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€\n",
    "# 1) í™˜ê²½ ì„¤ì •\n",
    "# â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€\n",
    "MODEL_PATH     = \"runs/train/Finetuned_428/weights/best.pt\"\n",
    "TEST_DIR       = \"tree/test\"    # ì˜ˆì¸¡í•  ì´ë¯¸ì§€ í´ë”\n",
    "OUTPUT_CSV     = \"tree_test.csv\"  # ì €ì¥í•  ê²°ê³¼ íŒŒì¼ëª…\n",
    "IMG_EXTS       = (\".jpg\", \".png\")\n",
    "LOC_THRESHOLDS = {\n",
    "    \"left\":   (0.0,  0.33),\n",
    "    \"center\": (0.33, 0.66),\n",
    "    \"right\":  (0.66, 1.0),\n",
    "}\n",
    "SIZE_THRESHOLDS = {\n",
    "    \"small\":  (0.0,  0.1),   # ë°•ìŠ¤ ë©´ì /ì „ì²´ ë©´ì \n",
    "    \"middle\": (0.1, 0.3),\n",
    "    \"big\":  (0.3,  1.0),\n",
    "}\n",
    "CLASS_NAMES = [\"branch\", \"root\", \"crown\", \"fruit\", \"gnarl\"]\n",
    "\n",
    "# â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€\n",
    "# 2) ëª¨ë¸ ë¡œë“œ\n",
    "# â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€\n",
    "model = YOLO(MODEL_PATH)\n",
    "\n",
    "# â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€\n",
    "# 3) ì˜ˆì¸¡í•  ì´ë¯¸ì§€ ëª©ë¡\n",
    "# â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€\n",
    "imgs = sorted([f for f in os.listdir(TEST_DIR) if f.lower().endswith(IMG_EXTS)])\n",
    "\n",
    "# â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€\n",
    "# 4) ê²°ê³¼ ë‹´ì„ ë¦¬ìŠ¤íŠ¸\n",
    "# â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€\n",
    "rows = []\n",
    "\n",
    "# â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€\n",
    "# 5) ì˜ˆì¸¡ ì‹¤í–‰\n",
    "# â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€\n",
    "for img_name in tqdm(imgs, desc=\"Processing test images\"):\n",
    "    img_path = os.path.join(TEST_DIR, img_name)\n",
    "    img = cv2.imread(img_path)\n",
    "    h, w = img.shape[:2]\n",
    "    area_total = w * h\n",
    "\n",
    "    # 5.1) ëª¨ë¸ ì˜ˆì¸¡\n",
    "    res = GetModelPredictResult(model, img_path)\n",
    "    xyxy  = res.boxes.xyxy.cpu().numpy()  # NÃ—4 ë°°ì—´\n",
    "    clses = res.boxes.cls.cpu().numpy()   # N ê¸¸ì´\n",
    "\n",
    "    # 5.2) í´ë˜ìŠ¤ë³„ y/n í”Œë˜ê·¸\n",
    "    flags = {c: \"n\" for c in CLASS_NAMES}\n",
    "    for cls in clses:\n",
    "        name = model.names[int(cls)]\n",
    "        if name in flags:\n",
    "            flags[name] = \"y\"\n",
    "\n",
    "    # 5.3) tree ë°•ìŠ¤ ìœ„ì¹˜/í¬ê¸° ê³„ì‚°\n",
    "    tree_boxes = [\n",
    "        (x1, y1, x2, y2)\n",
    "        for (x1, y1, x2, y2), cls in zip(xyxy, clses)\n",
    "        if model.names[int(cls)] == \"tree\"\n",
    "    ]\n",
    "    loc, size = \"\", \"\"\n",
    "    if tree_boxes:\n",
    "        # ë©´ì ìœ¼ë¡œ ê°€ì¥ í° ë°•ìŠ¤ ì„ íƒ\n",
    "        areas = [((x2 - x1) * (y2 - y1), (x1, y1, x2, y2)) for (x1, y1, x2, y2) in tree_boxes]\n",
    "        max_area, box = max(areas, key=lambda x: x[0])\n",
    "        x1, y1, x2, y2 = box\n",
    "        cx = ((x1 + x2) / 2) / w  # [0,1] ë²”ìœ„\n",
    "\n",
    "        # loc ê²°ì •\n",
    "        for key, (lo, hi) in LOC_THRESHOLDS.items():\n",
    "            if lo <= cx < hi:\n",
    "                loc = key\n",
    "                break\n",
    "\n",
    "        # size ê²°ì •\n",
    "        ratio = max_area / area_total\n",
    "        for key, (lo, hi) in SIZE_THRESHOLDS.items():\n",
    "            if lo <= ratio < hi:\n",
    "                size = key\n",
    "                break\n",
    "\n",
    "    # 5.4) í•œ í–‰ìœ¼ë¡œ í•©ì¹˜ê¸°\n",
    "    row = {\n",
    "        \"id\":        os.path.splitext(img_name)[0],\n",
    "        \"branch_yn\": flags[\"branch\"],\n",
    "        \"root_yn\":   flags[\"root\"],\n",
    "        \"crown_yn\":  flags[\"crown\"],\n",
    "        \"fruit_yn\":  flags[\"fruit\"],\n",
    "        \"gnarl_yn\":  flags[\"gnarl\"],\n",
    "        \"loc\":       loc,\n",
    "        \"size\":      size,\n",
    "    }\n",
    "    rows.append(row)\n",
    "\n",
    "# â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€\n",
    "# 6) DataFrame â†’ CSV ì €ì¥\n",
    "# â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€\n",
    "df = pd.DataFrame(rows)\n",
    "\n",
    "# encoding=\"utf-8-sig\" ì¸ìê°€ ì—†ìœ¼ë©´ í•œê¸€ì´ ê¹¨ì§\n",
    "df.to_csv(OUTPUT_CSV, index=False, encoding=\"utf-8-sig\")\n",
    "print(f\"âœ… ì˜ˆì¸¡ ê²°ê³¼ë¥¼ {OUTPUT_CSV}ì— ì €ì¥í–ˆìŠµë‹ˆë‹¤.\")\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "HTPProject",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "name": "python",
   "version": "3.10.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
